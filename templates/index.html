<!--<a href="/exec" class="button"> This link will invoke Parse method </a> -->
<html>
<body>
<style>
@import url(https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css);
@import url(https://fonts.googleapis.com/css?family=Comfortaa);

body {
  font-family: 'Comfortaa', cursive;
  background: #c7b284;
  color: #FFF;
}
.jumbotron h1 {
  color: #1b1a0a;
}


footer {
  margin-bottom: 0 !important;
  margin-top: 80px;
}
footer p {
  margin: 0;
  padding: 0;
}
span.icon {
  margin: 0 5px;
  color: #D64541;
}
h2 {
  color: #BDC3C7;
  text-transform: uppercase;
  letter-spacing: 1px;
}
.mrng-60-top {
  margin-top: 60px;
}
/* Global Button Styles */
a.animated-button:link, a.animated-button:visited {
  position: relative;
  display: block;
  margin: 30px auto 0;
  padding: 14px 15px;
  color: #fff;
  font-size:14px;
  font-weight: bold;
  text-align: center;
  text-decoration: none;
  text-transform: uppercase;
  overflow: hidden;
  letter-spacing: .08em;
  border-radius: 0;
  text-shadow: 0 0 1px rgba(0, 0, 0, 0.2), 0 1px 0 rgba(0, 0, 0, 0.2);
  -webkit-transition: all 1s ease;
  -moz-transition: all 1s ease;
  -o-transition: all 1s ease;
  transition: all 1s ease;
}
a.animated-button:link:after, a.animated-button:visited:after {
  content: "";
  position: absolute;
  height: 0%;
  left: 50%;
  top: 50%;
  width: 150%;
  z-index: -1;
  -webkit-transition: all 0.75s ease 0s;
  -moz-transition: all 0.75s ease 0s;
  -o-transition: all 0.75s ease 0s;
  transition: all 0.75s ease 0s;
}
a.animated-button:link:hover, a.animated-button:visited:hover {
  color: #FFF;
  text-shadow: none;
}
a.animated-button:link:hover:after, a.animated-button:visited:hover:after {
  height: 450%;
}
a.animated-button:link, a.animated-button:visited {
  position: relative;
  display: block;
  margin: 30px auto 0;
  padding: 14px 15px;
  color: #fff;
  font-size:14px;
  border-radius: 0;
  font-weight: bold;
  text-align: center;
  text-decoration: none;
  text-transform: uppercase;
  overflow: hidden;
  letter-spacing: .08em;
  text-shadow: 0 0 1px rgba(0, 0, 0, 0.2), 0 1px 0 rgba(0, 0, 0, 0.2);
  -webkit-transition: all 1s ease;
  -moz-transition: all 1s ease;
  -o-transition: all 1s ease;
  transition: all 1s ease;
}

/* Victoria Buttons */

a.animated-button.victoria-one {
  border: 2px solid #D24D57;
}
a.animated-button.victoria-one:after {
  background: #D24D57;
  -moz-transform: translateX(-50%) translateY(-50%) rotate(-25deg);
  -ms-transform: translateX(-50%) translateY(-50%) rotate(-25deg);
  -webkit-transform: translateX(-50%) translateY(-50%) rotate(-25deg);
  transform: translateX(-50%) translateY(-50%) rotate(-25deg);
}
a.animated-button.victoria-two {
  border: 2px solid #D24D57;
}
a.animated-button.victoria-two:after {
  background: #D24D57;
  -moz-transform: translateX(-50%) translateY(-50%) rotate(25deg);
  -ms-transform: translateX(-50%) translateY(-50%) rotate(25deg);
  -webkit-transform: translateX(-50%) translateY(-50%) rotate(25deg);
  transform: translateX(-50%) translateY(-50%) rotate(25deg);
}
#container {
	margin: 0px auto;
  width : "640";
  height:"480";
	border: 10px rgb(234, 240, 179) solid;
}
#divcontainer {
  position: relative;
	margin: 0px auto;
  width : "300";
  height:"300";
	border: 10px #333 solid;
}

#videoElement {
	background-color: #666;
}

/* Control the right side */
.right {
  right: 0;
  background-color:rgb(131, 124, 94);
}
.extra {
  width: 100%;
  height: 50px;
  top: 100%;
  background-color: rgb(141, 119, 49);
  border-bottom-left-radius: 15px;
  border-bottom-right-radius: 15px;
  line-height: 24px;
  text-indent: 5px;
  font-size: 20px;
}
/* If you want the content centered horizontally and vertically */
.centered {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  text-align: center;
}

/* Style the image inside the centered container, if needed */
.centered img {
  width: 150px;
  border-radius: 50%;
}

.button {
  background-color: #4CAF50; /* Green */
  border: none;
  color: white;
  padding: 15px 32px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
}


.video {
  position: relative;
  z-index: 1;
}
.canvas {
  position: absolute; 
  top: 100px; 
  color: #FFF; 
  text-align: center;
  font-size: 20px;
  background-color: rgba(221, 221, 221, 0.3);
  width: 640px;
  padding: 10px 0;
  z-index: 2147483647;


}
#overlay {
  position: relative; 
  
}

#inputVideo {
  position: relative; 
}

.form-radio
{
     -webkit-appearance: none;
     -moz-appearance: none;
     appearance: none;
     position: relative;
     background-color: rgb(186, 186, 245) ;
     color: rgb(129, 120, 41);
     top: 10px;
     height: 30px;
     width: 30px;
     left: 20px;
     border-radius: 50px;
     cursor: pointer;     
     margin-right: 7px;
     margin-left: 7px;

     outline: none;
}
.form-radio:checked::before
{
     position: absolute;
     font: 13px/1 'Open Sans', sans-serif;
     left: 11px;
     top: 7px;
     content: '\02143';
     transform: rotate(40deg);
}
.form-radio:hover
{
     background-color: rgb(55, 93, 143);
}
.form-radio:checked
{
     background-color: rgb(3, 44, 56);
}
label
{
     font: 18px/1.7 'Open Sans', sans-serif;
     color: darkblue;
     -webkit-font-smoothing: antialiased;
     -moz-osx-font-smoothing: grayscale;
     cursor: pointer;
     padding-left: 25px;
     } 
section {
  display: flex;
	flex-direction: column;
  flex-grow: 0;
  flex-shrink: 0;
  flex-basis: 30%;
}
</style>

<div class="jumbotron text-center">
  <div class="container">
    <h1>Advertisments based on human features recognized by AI </h1>
    <h2>Project portfolio</h2>
    <p style="color:#888;">Ahmed Elmahy</p>

    <button type="button" class="button" id="snap">Click here to Open Camera</button>
    <button type="button" class="button" id="play">Click here to run the model after you open the camera</button>
    </div>
    <h2 id="results" style = "color: darkblue">Results will show here</h2>
    <h2 id="accuracy" style = "color: darkblue">Accuracy will show here</h2>
  </div>

  <h4 style="color: darkblue">Kindly choose a model to show</h2>

  <div id="models">
    <input type="radio" name="model" value="gender" id="model" class="form-radio" checked><label for="radio-one"></label>Gender</label>
    <input type="radio" name="model" value="look" id="model" class="form-radio" ><label for="radio-one">Find your famous look</label>
    <input type="radio" name="model" value="glass" id="model" class="form-radio" ><label for="radio-one">Glasses</label>
    <input type="radio" name="model" value="Receding_Hairline" id="model" class="form-radio" ><label for="radio-one">Receding_Hairline</label>
    <input type="radio" name="model" value="Bags_Under_Eyes" id="model" class="form-radio" ><label for="radio-one">Bags_Under_Eyes</label>
    <input type="radio" name="model" value="Bald" id="model" class="form-radio" ><label for="radio-one">Bald</label>
    <input type="radio" name="model" value="Young" id="model" class="form-radio" ><label for="radio-one">Young</label>
    <input type="radio" name="model" value="Pale_Skin" id="model" class="form-radio" ><label for="radio-one">Pale_Skin</label>
    
  </div>


<div class="divcontainer">
    <video  onplay="onPlay(this)" id="inputVideo" autoplay muted ></video>
    <canvas id="overlay"/>
    
</div>

</div>

<h1 style="color:darkblue"><strong>Startup objective</strong></h1>
<h1 style="color:darkblue">You don't need to spend  money on irrelavant ads anymore. It's time for smart ads; Online and on the street.
  We build smart advertisement panels that personalize advertisements to the people walking in front of it. For example, the panel below
  is statis, but if we attached a camera and a small ardiuno to it, the advertisments shown will change to be specific for each pedestrian.
</h1>
<img src="{{ url_for('static', filename='panel.png')}}" alt="panel example">
<h1 style="color:darkblue"><strong>Expected costs</strong></h1>
<h1 style="color:darkblue">
  The same costs for an electronic advertisements panel plus price for the attached camera and cheap arduino to run the model. This should
  not exceed 50$ above the panel cost. 
</h1>
<br>

<h1 style="color:darkblue"><strong>Team</strong></h1>
<h1 style="color:darkblue">
    <ol>
        <li>I am working on the backend models, will improve them as much as possible</li>
        <li>An engineer for designing the panel, electricity, attaching the arduino and the screen 
          (I am trying now to estimate the costs for building a minimal viable product)
        </li>
      </ol>
</h1>
<br>
<h1 style="color:darkblue"><strong>Target customers</strong></h1>
<h1 style="color:darkblue">
  At the baseline, the panel will show ads which means any brand should be a target customer. But we have much more innovative plans to make
  our panel unique in the market:
  <ol>
      <li>We offer to specific industries, personalized ads such as women specifc ads; glasses ads for people wearing glasses;
         hair growth for bald people, products for the old, products for the young, products for men, products for people who look pale 
         possibly due to anemia and we will have unlimited ways to personalize ads</li>
      <li>Pay per view, a smart way to count the numbers of people looking at a specific ad and based on that number companies 
        will pay and it will also give them feedback about the attractiveness of their ads
      </li>
      <li>
        Very potential self learning plan: since the camera will detect people who look at specific ads that appear on the panel, We will build
        a model from these data.This model will detect features in people attracted to specific ads and when new people with similar features 
        walk by, these specifc ads will appear to them. #self learning 
      </li>
    </ol>
</h1>

<h1 style="color:darkblue"><strong>Privacy concern</strong></h1>
<h1 style="color:darkblue">
  This doesn't seem to be as limiting as I expected. There are public cameras everywhere and in almost every cafe, mall and restaurant
  and there were no legal activites against these cameras since they don't publish these image and since the cameras are in public place.
  Our panels will also be in public places, in malls, in the street and in conferences. In fact, we don't mind printing a large label above
  the panel to tell pedestrians that there is a camera and that the panel is smart. Actually, it can be a way to attract people.
</h1>
<br>
<h1 style="color:darkblue"><strong>How to test it ?</strong></h1>
<h1 style="color:darkblue"> 
  you can use your webcam or also you can also show your webcam a video running on youtube (the resolution will definitely affect 
  the accuracy). We don't claim that we are 100% accurate but at least it works in many situations specially for things like wearing 
  glasses. 
  
</h1>
<img src="{{ url_for('static', filename='test.png')}}" alt="panel example">

<script src="https://code.jquery.com/jquery-1.12.2.min.js" type="text/javascript"></script>
<script src="{{ url_for('static', filename="js/face-api.js")}}"></script>
<script>
  //width:640;
//height:480
// onplay="onPlay(this)"
  // <div id="viewer">
  //       <div id="cam">
  //           <video style="display:block;" id="video"  width="640" height="480" autoplay></video>
  //       </div>
  //   </div>

$(document).ready(function() {
  faceapi.tf.ENV.set('WEBGL_PACK', false)

 })
const videoEl = document.getElementById('inputVideo')
const canvas = document.getElementById('overlay')

async function run() {
  faceapi.loadTinyFaceDetectorModel('https://www.rocksetta.com/tensorflowjs/saved-models/face-api-js/')
  //tf.ENV.set('WEBGL_PACK', false)
  const stream = await navigator.mediaDevices.getUserMedia({ video: true })

    //navigator.mediaDevices.getUserMedia( {video: true})
    //.then((stream) => {
  videoEl.srcObject = stream;

  //onPlay(videoEl)
  //console.log("result")


  //  }).catch((err) => {console.log(err);});


   
  //await faceapi.loadTinyFaceDetectorModel("{{ url_for('static', filename='models/')}}")
  //await faceapi.loadFaceRecognitionModel("{{ url_for('static', filename='models/')}}")
  //await faceapi.loadMtcnnModel("{{ url_for('static', filename='models/')}}")
  //await faceapi.loadFaceRecognitionModel("{{ url_for('static', filename='models/')}}")
  //await faceapi.loadFaceLandmarkTinyModel("{{ url_for('static', filename='models/')}}");

  //await faceapi.loadFaceLandmarkTinyModel('https://www.rocksetta.com/tensorflowjs/saved-models/face-api-js/')


  

  //const alignedFaceTensors = await extractFaceTensors(input, alignedFaceBoxes)

  //const descriptors = await Promise.all(alignedFaceTensors.map(
  //))



}
/* async function getFullFaceDescription(blob, inputSize = 512) {
  // tiny_face_detector options
  let scoreThreshold = 0.5;
  const OPTION = new faceapi.TinyFaceDetectorOptions({
    inputSize,
    scoreThreshold
  });
  const useTinyModel = true;

  // fetch image to api
  let img = await faceapi.fetchImage(blob);

  // detect all faces and generate full description from image
  // including landmark and descriptor of each face
  let fullDesc = await faceapi
    .detectAllFaces(img, OPTION)
    .withFaceLandmarks(useTinyModel)
    .withFaceDescriptors();
  return fullDesc;
} */
/* const mtcnnForwardParams = {
  // limiting the search space to larger faces for webcam detection
  minFaceSize: 200
} */
function resizeCanvasAndResults(dimensions, canvas, results) {
    const { width, height } = dimensions instanceof HTMLVideoElement
        ? faceapi.getMediaDimensions(dimensions)
        : dimensions
    //canvas.width = width
    //canvas.height = height

    return results.map(res => res)
    //result = results[0]
    
    //return result.detection.forSize(width, height);
     
};


function drawDetections(dimensions, canvas, results) {
    //const resizedResults = resizeCanvasAndResults(dimensions, canvas, results)
    //faceapi.drawDetection(canvas, resizedResults.map(det => det.detection))
    //faceapi.drawDetection(canvas, resizedResults)
    
    //return canvas

};


// function drawLandmarks(dimensions, canvas, results, withBoxes = true) {
//     const resizedResults = this.resizeCanvasAndResults(dimensions, canvas, results)
//     if (withBoxes) {
//         faceapi.drawDetection(canvas, resizedResults.map(det => det.detection))
//     }
//     const faceLandmarks = resizedResults.map(det => det.landmarks)
//     const drawLandmarksOptions = { lineWidth: 2, drawLines: true, color: 'green' }
//     faceapi.drawLandmarks(canvas, faceLandmarks, drawLandmarksOptions)
// };


async function onPlay(videoEl) {

  const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 416, scoreThreshold: 0.2 })

  var result = await faceapi.detectSingleFace(videoEl, options)

  console.log(result)

  if (result) {

    //const resizedResults = resizeCanvasAndResults(videoEl, document.getElementById('overlay'), [result])
//     if (withBoxes) {
    //drawDetections(videoEl, document.getElementById('overlay'),  [result])
    //var canvas2 = document.getElementById('canvas2');
    const resizedResults = resizeCanvasAndResults(videoEl, canvas, [result])
    console.log("resizedresults")
    console.log(resizedResults)
    cropped_box = resizedResults.map(resizedResults => resizedResults.box)
    dim_x = Math.round(cropped_box.map(box => box.x))
    dim_y = Math.round(cropped_box.map(box => box.y))
    dim_width = Math.round(cropped_box.map(box => box.width)) 
    dim_height = Math.round(cropped_box.map(box => box.height)) 

    
    var crop = {
      top :  Math.max((dim_y - 55),0),
      left : dim_x ,
      width : dim_width + 20,
      height : dim_height + 50,
    }


    //var c = document.getElementById("overlay");

    var ctx = canvas.getContext("2d");
    //canvas.width = crop.width;
    //canvas.height = crop.height;

    //ctx.rect(crop.left,crop.top, crop.width, crop.height);
    //ctx.stroke();


    //var canvas_cropped = document.createElement("canvas");
    console.log([ctx,crop.top,crop.left])

    //var ctx = cropped_can.getContext("2d"); // so we can draw
    //ctx.drawImage(videoEl, ,);
    
    canvas.width = 128
    canvas.height = 128
    //canvas.getContext("2d").drawImage(video, 0, 0, 300, 300);
    ctx.drawImage(videoEl, crop.left, crop.top, crop.width, crop.height, 0, 0, 128, 128);
    send_canvas_ctx();
    //send_canvas_ctx(canvas);
    //cropped_can = canvas_withleft_top[0]
    
   
    
//       $("#res").show();
}
  else {
    console.log("else")
    setTimeout(() => onPlay(videoEl),200)
  }


    
//     }
            //console.log(result)
            //drawLandmarks(videoEl, document.getElementById('overlay'), [result], true)
}

  //let fullDesc = await faceapi
  // .detectAllFaces(document.getElementById('inputVideo'))
  //return fullDesc;
  //const mtcnnResults = await faceapi.mtcnn(document.getElementById('inputVideo'), mtcnnForwardParams)

  //const detectionsArray = fullDesc.map(res => res.faceDetection)
  //faceapi.drawDetection('overlay',detectionsArray, { withScore: false })
  //faceapi.drawLandmarks('overlay', mtcnnResults.map(res => res.faceLandmarks), { lineWidth: 4, color: 'red' })
  //setTimeout(() => onPlay(videoEl),200)

  


//faceTensor => faceapi.computeFaceDescriptor(faceTensor)
//const alignedFaceBoxes = results.map(
 // ({ faceLandmarks }) => faceLandmarks.align()
//)


//const options = new faceapi.MtcnnOptions(mtcnnParams)
//const input = document.getElementById('inputVideo')
//const fullFaceDescriptions = await faceapi.detectAllFaces(input, options).withFaceLandmarks().withFaceDescriptors()


//<div id="res" style="cursor:pointer;height:30px;"></div>
//var video = document.querySelector("#videoElement");
// var video = document.getElementById('inputVideo');

// var ctx;
// var canvas = document.createElement('canvas');
// // Converts image to canvas; returns new canvas element
// canvas.width="640"
// canvas.height="480"


document.getElementById("snap").addEventListener("click", function() {
  run()
});
document.getElementById("play").addEventListener("click", function() {
  onPlay(videoEl)
});




// function ping() {
// 	window.fetch('/snap_a_signal')
// 	  .then(function(response) {
// 		      return response.text()
// 		    }).then(function(body) {
//           if (body["result"] == "0") {
//             console.log(body["result"] == "0");
//           } else {
// 				    console.log(body);
//           }
// 		    });
// }


function send_canvas_ctx() {
    var selected_model = document.querySelector('input[name="model"]:checked').value;
    console.log(selected_model)
    input_data = canvas.toDataURL('image/png');
    //console.log(input_data)
	  window.fetch('/snap_a_signal', {
  		method: 'POST',
  		headers: {
    		'Content-Type': 'application/json'
  		},
  		body: JSON.stringify({
    		data: input_data,
        selected_model: selected_model
  		})
	}).then((response) => response.json()).then((json) => {
    document.getElementById('results').innerHTML = json["results"]
    document.getElementById('accuracy').innerHTML = json["accuracy"]
    
    console.log("else2")
    //const videoEl = document.getElementById('inputVideo')
    onPlay(videoEl)
  })
  
  }
          



</script>

</body>
</html>
